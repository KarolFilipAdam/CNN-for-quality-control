{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2385a9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "### IMPORTS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94523eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import scipy # This is new!\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "import scipy.integrate as integrate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model,Sequential,Model\n",
    "from tensorflow.keras.utils import load_img, img_to_array \n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.applications import MobileNetV2,VGG16\n",
    "from keras.applications import InceptionV3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72da730",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATASET GENERAL FUNCTION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetGeneralFunction(trainPath,validatePath,bSize,sizeY,sizeX):\n",
    "    \n",
    "    trainData_path = trainPath\n",
    "    validateData_path = validatePath\n",
    "\n",
    "    trainDatagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range = 10,\n",
    "        width_shift_range =  0.15,\n",
    "        height_shift_range =  0.15,\n",
    "        shear_range = 0.5,\n",
    "        zoom_range = 0.1,\n",
    "        channel_shift_range = 15,\n",
    "        horizontal_flip = True\n",
    "    )\n",
    "    testDatagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "    trainGenerator = trainDatagen.flow_from_directory(\n",
    "        trainData_path,\n",
    "        target_size = (sizeY,sizeX),\n",
    "        batch_size = bSize,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "    validationGenerator = testDatagen.flow_from_directory(\n",
    "        validateData_path,\n",
    "        target_size = (sizeY,sizeX),\n",
    "        batch_size = bSize,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "    \n",
    "    return trainGenerator, validationGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATASET GENERAL FUNCTION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARCHITECTURES ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelKarol(inputY,inputX,channel):    \n",
    "    model = Sequential()\n",
    "\n",
    "    # First Block\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), strides=(2,2), input_shape=(inputY,inputX,channel), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), strides=(2,2), input_shape=(300,300,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(2,2), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "  \n",
    "    model.add(Conv2D(64, kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(2,2), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(1,1), strides=(2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(2,2), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(1,1), strides=(2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(2,2), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(1,1), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(1,1), strides=(2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37875599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelMobile(inputY,inputX,channel):\n",
    "\n",
    "    base_model = MobileNetV2(input_shape=(inputY, inputX, channel), include_top=False, weights='imagenet')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c784b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelVGG(inputY,inputX,channel):\n",
    "    input_shape = (inputY, inputX, channel)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c64a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelGoogleNet(inputY,inputX,channel):\n",
    "    base_model = InceptionV3(input_shape=(inputY, inputX, channel), include_top=False, weights='imagenet')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f741de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATASET GENERAL FUNCTION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5770a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIT FUNKCIA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "history = model.fit(\n",
    "    trainGenerator,\n",
    "    steps_per_epoch=len(trainGenerator),\n",
    "    epochs=80,\n",
    "    validation_data=validationGenerator,\n",
    "    validation_steps=len(validationGenerator),\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ee612",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIT FUNKCIA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRAF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "model.save(\"/kaggle/working/model2.h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRAF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL TEST ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde26183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"\",compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e80e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba13111",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDatagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = testDatagen.flow_from_directory(\n",
    "    '',\n",
    "        target_size = (487,400),\n",
    "        batch_size = 5,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL TEST ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
